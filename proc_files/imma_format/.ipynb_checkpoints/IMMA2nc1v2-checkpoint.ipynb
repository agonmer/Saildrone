{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-00e887c0fd87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\xa0\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mancillary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-00e887c0fd87>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\xa0\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mancillary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Purpose: Python module for processing and saving IMMA1 to netCDF 4\n",
    "# same shortnames are used as the IMMA1 data, please refere to IMMA1 documentation for more details  \n",
    "# IMMA1 documentation is at https://rda.ucar.edu/datasets/ds548.0/#!docs\n",
    "# History: developed by Zhankun Wang between Oct 2016 and May 2017 for the BEDI ICOADS project\n",
    "# (c) NOAA National Centers for Environmental Information\n",
    "# contact: zhankun.wang@noaa.gov  \n",
    "\n",
    "import uuid\n",
    "import time\n",
    "#import netCDF4\n",
    "#import numpy as np\n",
    "import os\n",
    "import jdutil\n",
    "\n",
    "# change the path to where the program and documents are saved. one level above \n",
    "fpath_default = '/users/senyastein/Documents/GitHub/Saildrone/proc_files/imma_format/'\n",
    "#fpath_default = '/nodc/projects/tsg/zwang/ICOADS/codes'\n",
    "# change to where the python codes saved\n",
    "os.chdir(fpath_default)\n",
    "\n",
    "time_fmt = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "\n",
    "att_doc = 2\n",
    "if att_doc == 1:\n",
    "    f = open('%sIMMA1.1662.10' %fpath_default, 'r') #change this to insert your IMMA table fp\n",
    "    lines = f.readlines()\n",
    "    lines = [x.rstrip(\"\\r\\n\") for x in lines]\n",
    "    f.close()\n",
    "    No = [x.split(',')[0] for x in lines]\n",
    "    length = [x.split(',')[1] for x in lines]\n",
    "    abbr = [x.split(',')[2].upper() for x in lines]\n",
    "    longname = [x.split(',')[3] for x in lines]\n",
    "    min_values = [x.split(',')[4] for x in lines]\n",
    "    max_values = [x.split(',')[5] for x in lines]\n",
    "    units = [x.split(',')[6] for x in lines]\n",
    "    comments = [x.split(',')[7:] for x in lines]\n",
    "elif att_doc == 2:\n",
    "    f = open('%sIMMA1.1662.10' %fpath_default, 'r') # IMMA table here as well ?\n",
    "    lines = f.readlines()\n",
    "    lines = [x.rstrip(\"\\r\\n\") for x in lines]\n",
    "    lines = [x.rstrip(\"\\xa0\") for x in lines]\n",
    "    f.close()\n",
    "    ancillary = [x.split(',')[1] for x in lines]\n",
    "    names = [x.split(',')[2] for x in lines]\n",
    "    units = [x.split(',')[5] for x in lines]\n",
    "    min_values = [x.split(',')[6] for x in lines]\n",
    "    max_values = [x.split(',')[7] for x in lines] \n",
    "    longname = [x.split(',')[9] for x in lines]\n",
    "    flagvalues = [x.split(',')[10] for x in lines]\n",
    "    # flagvalues = [x.replace(' ',',') for x in flagvalues]\n",
    "    flagmeanings = [x.split(',')[17] for x in lines]\n",
    "    standardname = [x.split(',')[18] for x in lines]\n",
    "    scaledtype = [x.split(',')[16] for x in lines]\n",
    "    comments = [x.split(',')[19] for x in lines]\n",
    "    keywords_list = [x.split(',')[22] for x in lines]\n",
    "    abbr = [x.split('-')[0] for x in names]\n",
    "    abbr_e = [x.split('-')[1] if '-' in x else x for x in names]\n",
    "    flagvalues = [x if 'blank' not in x else '' for x in flagvalues]\n",
    "else:\n",
    "    print('Error: No proper variable attributes document is found!')\n",
    "    \n",
    "\n",
    "parameters  = {}\n",
    "attachment = {}\n",
    "atta_list = [0,1,5,6,7,8,9,95,96,97,98,99]\n",
    "attachment['00'] = 'CORE'\n",
    "parameters['00'] = ('YR','MO','DY','HR','LAT','LON','IM','ATTC','TI','LI','DS','VS','NID','II','ID','C1','DI','D','WI','W','VI','VV','WW','W1','SLP','A','PPP','IT','AT','WBTI','WBT','DPTI','DPT','SI','SST','N','NH','CL','HI','H','CM','CH','WD','WP','WH','SD','SP','SH')\n",
    "attachment['01'] = 'ICOADS ATTACHMENT'\n",
    "parameters['01'] = ('BSI','B10','B1','DCK','SID','PT','DUPS','DUPC','TC','PB','WX','SX','C2','SQZ','SQA','AQZ','AQA','UQZ','UQA','VQZ','VQA','PQZ','PQA','DQZ','DQA','ND','SF','AF','UF','VF','PF','RF','ZNC','WNC','BNC','XNC','YNC','PNC','ANC','GNC','DNC','SNC','CNC','ENC','FNC','TNC','QCE','LZ','QCZ')\n",
    "attachment['05'] = 'IMMT-5/FM13 ATTACHMENT'\n",
    "parameters['05'] = ('OS','OP','FM','IMMV','IX','W2','WMI','SD2','SP2','SH2','IS','ES','RS','IC1','IC2','IC3','IC4','IC5','IR','RRR','TR','NU','QCI','QI1','QI2','QI3','QI4','QI5','QI6','QI7','QI8','QI9','QI10','QI11','QI12','QI13','QI14','QI15','QI16','QI17','QI18','QI19','QI20','QI21','HDG','COG','SOG','SLL','SLHH','RWD','RWS','QI22','QI23','QI24','QI25','QI26','QI27','QI28','QI29','RH','RHI','AWSI','IMONO')\n",
    "attachment['06'] = 'MODEL QUALITY CONTROL ATTACHMENT'\n",
    "parameters['06'] = ('CCCC','BUID','FBSRC','BMP','BSWU','SWU','BSWV','SWV','BSAT','BSRH','SRH','BSST','MST','MSH','BY','BM','BD','BH','BFL')\n",
    "attachment['07'] = 'SHIP METADATA ATTACHMENT'\n",
    "parameters['07'] = ('MDS','C1M','OPM','KOV','COR','TOB','TOT','EOT','LOT','TOH','EOH','SIM','LOV','DOS','HOP','HOT','HOB','HOA','SMF','SME','SMV')\n",
    "attachment['08'] = 'NEAR-SURFACE OCEANOGRAPHIC DATA ATTACHMENT'\n",
    "parameters['08'] = ('OTV','OTZ','OSV','OSZ','OOV','OOZ','OPV','OPZ','OSIV','OSIZ','ONV','ONZ','OPHV','OPHZ','OCV','OCZ','OAV','OAZ','OPCV','OPCZ','ODV','ODZ','PUID')\n",
    "attachment['09'] = 'EDITED CLOUD REPORT ATTACHMENT'\n",
    "parameters['09'] = ('CCE','WWE','NE','NHE','HE','CLE','CME','CHE','AM','AH','UM','UH','SBI','SA','RI')\n",
    "attachment['95'] = 'REANALYSES QC/FEEDBACK ATTACHMENT'\n",
    "parameters['95'] = ('ICNR','FNR','DPRO','DPRP','UFR','MFGR','MFGSR','MAR','MASR','BCR','ARCR','CDR','ASIR')\n",
    "attachment['96'] = 'ICOADS VALUE-ADDED DATABASE ATTACHMENT'\n",
    "parameters['96'] = ('ICNI','FNI','JVAD','VAD','IVAU1','JVAU1','VAU1','IVAU2','JVAU2','VAU2','IVAU3','JVAU3','VAU3','VQC','ARCI','CDI','ASII')\n",
    "attachment['97'] = 'ERROR ATTACHMENT'\n",
    "parameters['97'] = ('ICNE','FNE','CEF','ERRD','ARCE','CDE','ASIE')\n",
    "attachment['98'] = 'UNIQUE ID ATTACHMENT'\n",
    "parameters['98'] = ('UID','RN1','RN2','RN3','RSA','IRF')\n",
    "attachment['99'] = 'SUPPLEMENTAL DATA ATTACHMENT'\n",
    "parameters['99'] = ('ATTE','SUPD')\n",
    "\n",
    "def get_var_att(var):\n",
    "    idx = abbr.index(var)\n",
    "    if att_doc == 1:\n",
    "        att = {'abbr':var,'longname':longname[idx],'min_v':min_values[idx],'max_v': max_values[idx],'unit':units[idx], 'comment': comments[idx]}\n",
    "    elif att_doc == 2:\n",
    "        att = {'abbr':var,'ancillary':ancillary[idx],'standardname':standardname[idx],'scaledtype':scaledtype[idx],'longname':longname[idx],'min_v':min_values[idx],'max_v': max_values[idx],'unit':units[idx], 'comment': comments[idx], 'flagvalues': flagvalues[idx], 'flagmeanings':flagmeanings[idx]}\n",
    "    else:\n",
    "        print('Error: No attribute document found.')\n",
    "    return att\n",
    "\n",
    "def get_ancillary(anc_QC, check_list):\n",
    "    var = anc_QC.split(';')\n",
    "    var = [x.split('-')[0].strip() for x in var]\n",
    "    var = [x for x in var if x in check_list ]\n",
    "    return ' '.join(var)\n",
    "\n",
    "def getParameters(i):\n",
    "    return parameters[\"%02d\" % i]\n",
    "\n",
    "\n",
    "def save(out_file,data, **kwargs):\n",
    "    def duration(seconds):\n",
    "        t= []\n",
    "    for dm in (60, 60, 24, 7):\n",
    "        seconds, m = divmod(seconds, dm)\n",
    "        t.append(m)\n",
    "    t.append(seconds)\n",
    "    return ''.join('%d%s' % (num, unit)\n",
    "             for num, unit in zip(t[::-1], 'W DT H M S'.split())\n",
    "             if num)\n",
    "    def get_keywords(data):\n",
    "        keywords = []\n",
    "    for var in data.data.keys():\n",
    "        if var in abbr:\n",
    "            idx = abbr.index(var)\n",
    "        if len(keywords_list[idx])>0:\n",
    "            keywords.append(keywords_list[idx])\n",
    "            # print var, keywords_list[idx]  \n",
    "    keywords = list(set(keywords))\n",
    "    keywords = ['Earth Science > %s' %x for x in keywords]\t\t\t\t\t\t\t\t\t\t\t\t\t\t      \n",
    "    keywords = ', '.join(keywords)\n",
    "    return keywords\n",
    "\n",
    "    def Add_gattrs(ff):\n",
    "        lon_min = min(data['LON'])\n",
    "        lon_max = max(data['LON'])\n",
    "        lat_min = min(data['LAT'])\n",
    "        lat_max = max(data['LAT'])\n",
    "        start_time = min(data.data['Julian'])\n",
    "        end_time = max(data.data['Julian'])\n",
    "        dur_time = (end_time-start_time)*24.0*3600.0\n",
    "        start_time = jdutil.jd_to_datetime(start_time)\n",
    "        start_time_s = \"%s-%02d-%02dT%02d:%02d:%02dZ\" %(start_time.year,start_time.month,start_time.day,start_time.hour,start_time.minute,start_time.second)\n",
    "        end_time = jdutil.jd_to_datetime(end_time)\n",
    "        end_time_s = \"%s-%02d-%02dT%02d:%02d:%02dZ\" %(end_time.year,end_time.month,end_time.day,end_time.hour,end_time.minute,end_time.second)\n",
    "        version = out_file.split('_')[1]\n",
    "    #start_time_s = time.strftime(time_fmt,time.gmtime(float(start_time)))\n",
    "    #end_time_s = time.strftime(time_fmt,time.gmtime(float(end_time)))\n",
    "        ff.ncei_template_version = \"NCEI_NetCDF_Point_Template_v2.0\"\n",
    "        ff.featureType = \"point\"\n",
    "        ff.title = \"International Comprehensive Ocean-Atmosphere Data Set (ICOADS) %s data collected from %s to %s.\" %(version, start_time_s, end_time_s) \n",
    "        ff.summary = \"This file contains ICOADS %s data in netCDF4 format collected from %s to %s. The International Comprehensive Ocean-Atmosphere Data Set (ICOADS) offers surface marine data spanning the past three centuries, and simple gridded monthly summary products for 2-degree latitude x 2-degree longitude boxes back to 1800 (and 1degreex1degree boxes since 1960)--these data and products are freely distributed worldwide. As it contains observations from many different observing systems encompassing the evolution of measurement technology over hundreds of years, ICOADS is probably the most complete and heterogeneous collection of surface marine data in existence.\" %(version, start_time_s, end_time_s)\n",
    "        ff.keywords = get_keywords(data);\n",
    "        ff.Conventions = \"CF-1.6, ACDD-1.3\"\n",
    "        ff.id = out_file.split('.nc')[0].replace('IMMA1','ICOADS')\n",
    "        ff.naming_authority = \"gov.noaa.ncei\"\n",
    "        #ff.source = \"http://rda.ucar.edu/data/ds548.0/imma1_r3.0.0/%s.tar\" %out_file.split('-')[0]\n",
    "        ff.source = \"%s.gz\" %out_file.split('.nc')[0]\n",
    "        ff.processing_level = \"Restructured from IMMA1 format to NetCDF4 format.\"\n",
    "        ff.acknowledgement = \"Conversion of ICOADS data from IMMA1 to netCDF format by NCEI is supported by the NOAA Big Earth Data Initiative (BEDI).\"\n",
    "        ff.license = \"These data may be redistributed and used without restriction.\"\n",
    "        ff.standard_name_vocabulary = \"CF Standard Name Table v31\"\n",
    "        ff.date_created =  time.strftime(time_fmt,time.gmtime())\n",
    "        ff.creator_name = \"NCEI\"\n",
    "        ff.creator_email = \"ncei.info@noaa.gov\"\n",
    "        ff.creator_url = \"https://www.ncei.noaa.gov/\"\n",
    "        ff.institution = \"National Centers for Environmental Information (NCEI), NOAA\"\n",
    "        ff.project = \"International Comprehensive Ocean-Atmosphere Data Set (ICOADS) Project\"\n",
    "        ff.publisher_name = \"NCEI\"\n",
    "        ff.publisher_email = \"ncei.info@noaa.gov\"\n",
    "        ff.publisher_url = \"https://www.ncei.noaa.gov/\"\n",
    "        ff.geospatial_bounds = \"POLYGON ((%.4f %.4f,%.4f %.4f,%.4f %.4f,%.4f %.4f,%.4f %.4f))\" %(lon_min,lat_min,lon_min,lat_max,lon_max,lat_max,lon_max,lat_min,lon_min,lat_min)\n",
    "        ff.geospatial_bounds_crs = \"EPSG:4326\"\n",
    "        ff.geospatial_lat_min = float(\"%.4f\" %(lat_min))\n",
    "        ff.geospatial_lat_max = float(\"%.4f\" %(lat_max)) \n",
    "        ff.geospatial_lon_min = float(\"%.4f\" %(lon_min))\n",
    "        ff.geospatial_lon_max = float(\"%.4f\" %(lon_max)) \n",
    "        ff.geospatial_lat_units = \"degrees_north\"\n",
    "        ff.geospatial_lon_units = \"degrees_east\"\n",
    "        ff.time_coverage_start = start_time_s\n",
    "        ff.time_coverage_end = end_time_s\n",
    "        ff.time_coverage_duration = 'P' + duration(dur_time)\n",
    "        ff.time_coverage_resolution = \"vary\"\n",
    "        ff.uuid = str(uuid.uuid4())\n",
    "        ff.sea_name = \"World-Wide Distribution\"\n",
    "        ff.creator_type = \"group\"\n",
    "        ff.creator_institution = \"NOAA National Centers for Environmental Information (NCEI)\"\n",
    "        ff.publisher_type = \"institution\"\n",
    "        ff.publisher_institution = \"NOAA National Centers for Environmental Information (NCEI)\"\n",
    "        ff.program = \"\"\n",
    "        ff.contributor_name = \"Zhankun Wang; ICOADS team\"\n",
    "        ff.contributor_role = \"ICOADS Data Conversion to NetCDF; ICOADS IMMA1 Data Provider\"\n",
    "        ff.date_modified = time.strftime(time_fmt,time.gmtime())\n",
    "        ff.date_issued = time.strftime(time_fmt,time.gmtime())\n",
    "        ff.date_metadata_modified = time.strftime(time_fmt,time.gmtime())\n",
    "        ff.product_version = \"ICOADS %s netCDF4\" %version\n",
    "        ff.keywords_vocabulary = \"Global Change Master Directory (GCMD) 2015. GCMD Keywords, Version 8.1.\"\n",
    "        ff.cdm_data_type = 'Point'\n",
    "        ff.metadata_link = 'http://rda.ucar.edu/datasets/ds548.0/#!docs'\n",
    "    if len(set(data.data['IM'])) == 1:\n",
    "        ff.IMMA_Version = str(data.data['IM'][0])\n",
    "    else: \n",
    "        print('%s: check IMMA version' %out_file)\n",
    "    if len(set(data.data['RN1'])) == 1:\n",
    "        ff.Release_Number_Primary = str(data.data['RN1'][0])\n",
    "    else: \n",
    "        print('%s: check Release_Number_Primary' %out_file)\n",
    "    if len(set(data.data['RN2'])) == 1:\n",
    "        ff.Release_Number_Secondary = str(data.data['RN2'][0])\n",
    "    else: \n",
    "        print('%s: check Release_Number_Secondary' %out_file)\n",
    "    if len(set(data.data['RN3'])) == 1:\n",
    "        ff.Release_Number_Tertiary = str(data.data['RN3'][0])\n",
    "    else: \n",
    "        print('%s: check Release_Number_Tertiary' %out_file)\n",
    "    if len(set(data.data['RSA'])) == 1:\n",
    "        ff.Release_status_indicator = str(data.data['RSA'][0])\n",
    "    else: \n",
    "        print('%s: check RSA' %out_file)\n",
    "    #ff.comment = \"\"      \n",
    "    ff.references = 'http://rda.ucar.edu/datasets/ds548.0/docs/R3.0-citation.pdf'\n",
    "    ff.history = time.strftime(time_fmt,time.gmtime()) + \": Converted from IMMA1 format to netCDF4 format by Z.W. \"\n",
    "\n",
    "    fpath = kwargs.get('fpath')\n",
    "    if fpath is None:\n",
    "        fpath = fpath_default\n",
    "    #ftxt = open(\"%s%s.txt\" %(fpath,out_file[0:-3]), 'w')\n",
    "    #ftxt.write('Saving to %s ...\\n' %out_file); \n",
    "        ff = netCDF4.Dataset(fpath + out_file.replace('IMMA1','ICOADS'), 'w', format='NETCDF4')\n",
    "        Add_gattrs(ff)\n",
    "    \n",
    "\n",
    "    ff.createDimension('obs',len(data.data['YR']))\n",
    "    '''\n",
    "    # save time in Julian Days\n",
    "    timein = ff.createVariable('time','f8',('obs',),zlib=True,complevel=4)\n",
    "    timein.long_name = \"time\" \n",
    "    timein.standard_name = \"time\" \n",
    "    timein.units = \"days since -4713-1-1 12:0:0 \" \n",
    "    timein.calendar = \"julian\" \n",
    "    timein.axis = \"T\" \n",
    "    timein.comment = \"Julian days since noon on January 1, 4713 BC. Missing values of date (DD in date) are replaced by 0 and missing values in HR are filled with 0.0 in this calculation. See actural values in date, HR for reference.\"  \n",
    "    timein[:] = data.data['Julian'][:]\n",
    "    '''\n",
    "    # save time in Julian Days since the beginning of ICOADS data: 1662-10-15 12:00:00\n",
    "    timein = ff.createVariable('time','f8',('obs',),zlib=True,complevel=4)\n",
    "    timein.long_name = \"time\" \n",
    "    timein.standard_name = \"time\" \n",
    "    timein.units = \"days since 1662-10-15 12:00:00\" \n",
    "    timein.calendar = \"julian\" \n",
    "    timein.axis = \"T\" \n",
    "    timein.comment = \"Julian days since the beginning of the ICOADS record, which is 1662-10-15 12:00:00. Missing values of date (DD in date) are replaced by 0 and missing values in HR are filled with 0.0 in this calculation. See actual values in date, HR for reference.\"  \n",
    "    timein[:] = data.data['Julian1'][:]\n",
    "\n",
    "\n",
    "    # save date in YYYYMMDD\n",
    "    ff.createDimension('DATE_len',len(data.data['DATE'][0]))\n",
    "    date = ff.createVariable('date','S1',('obs','DATE_len',),zlib=True,complevel=4)\n",
    "    date.long_name = \"date in YYYYMMDD\" \n",
    "    #date.valid_min = '16000101'\n",
    "    #date.valid_max = '20241231'\n",
    "    date.format = 'YYYYMMDD'\n",
    "    #date.axis = \"T\" \n",
    "    date.comment = \"YYYY: four digital year, MM: two digital month and DD: two digital date. Missing values of DD have been filled with 99.\"  \n",
    "    date[:] = [netCDF4.stringtochar(np.array(x)) for x in data.data['DATE']]\n",
    "    #print data.data['YR']\n",
    "    crsout = ff.createVariable('crs','i')\n",
    "    crsout.grid_mapping_name = \"latitude_longitude\"\n",
    "    crsout.epsg_code = \"EPSG:4326\"\n",
    "    crsout.semi_major_axis = 6378137.0\n",
    "    crsout.inverse_flattening = 298.257223563\n",
    "    #crsout.comment = ''\n",
    "    dim_list = []\n",
    "    dim_dir = []\n",
    "    exclusives = ['YR','MO','DY','SUPD','IM','ATTC','ATTE','RN1','RN2','RN3','RSA']\n",
    "    '''\n",
    "    exclusives_2 = ['CDE','CDI','YR','MO','DY','SUPD','IM','ATTC','ATTE','RN1','RN2','RN3','RSA','ICNR','FNR','DPRO','DPRP','UFR','MFGR','MFGSR','MAR','MASR','BCR','ARCR','CDR','ASIR'] \n",
    "    for atta in atta_list:\n",
    "    var_list = getParameters(atta)\n",
    "    for var in var_list:\n",
    "      if var in exclusives_2:\n",
    "        pass\n",
    "      else:\n",
    "        print var\n",
    "        att = get_var_att(var)\n",
    "        if 'flagvalues' in att:\n",
    "        if len(att['flagvalues']) > 0:\n",
    "            print var, att['flagvalues'], att['flagmeanings']\n",
    "            foo = att['flagvalues'].split(' ')\n",
    "            foo_m = att['flagmeanings'].split(' ')\n",
    "            for x,y in zip(foo,foo_m): print('%s: %s' %(x,y))\n",
    "    '''\n",
    "    for atta in atta_list:\n",
    "        var_list = getParameters(atta)\n",
    "    for var in var_list:\n",
    "        if var in data.data.keys():\n",
    "            if var in exclusives:\n",
    "                pass\n",
    "        else:\n",
    "            start = time.time()\n",
    "            #ftxt.write('%s start at %s. ' %(var,time.strftime(time_fmt,time.gmtime()))); \n",
    "            index = [i for i, x in enumerate(data.data[var]) if x is not None]\n",
    "            # print var,data[var],index[0],data.data[var][index[0]]\n",
    "            \n",
    "            if type(data.data[var][index[0]]) is int:\n",
    "    \n",
    "                dataout = ff.createVariable(var,'i2',('obs',),fill_value = -99,zlib=True,complevel=4)\n",
    "                #dataout = ff.createVariable(var,'f4',('obs',),zlib=True,complevel=4)\n",
    "                dataout[index] = [data.data[var][idx] for idx in index]\n",
    "            elif type(data.data[var][index[0]]) is float:\n",
    "                if var == 'LAT':\n",
    "                    dataout = ff.createVariable('lat','f4',('obs',),zlib=True,complevel=4)\n",
    "                elif var == 'LON':\n",
    "                    dataout = ff.createVariable('lon','f4',('obs',),zlib=True,complevel=4)\n",
    "                else:\n",
    "                    dataout = ff.createVariable(var,'f4',('obs',),fill_value = float(-9999),zlib=True,complevel=4)\n",
    "                    dataout[index] = [data.data[var][idx] for idx in index]\n",
    "            elif type(data.data[var][index[0]]) is str:\n",
    "            #print var\n",
    "                if var == 'SUPD':\n",
    "                #ll = max([len(x) if x is not None else 0 for x in data.data[var] ])\n",
    "                #data.data[var] = [x.ljust(ll) if x is not None else None for x in data.data[var]]\n",
    "                    pass\n",
    "                else:\n",
    "                    ll = len(data.data[var][index[0]])\n",
    "                if ll not in dim_list:\n",
    "                    ff.createDimension('%s_len' %var,ll)\n",
    "                    dataout = ff.createVariable(var,'S1',('obs','%s_len' %var,),zlib=True,complevel=4)\n",
    "                    dim_list.append(ll)\n",
    "                    dim_dir.append(var)\n",
    "                else:\n",
    "                    idx = dim_list.index(ll)\n",
    "                    dataout = ff.createVariable(var,'S1',('obs','%s_len' %dim_dir[idx],),zlib=True,complevel=4)  \n",
    "                    dataout[index] = [netCDF4.stringtochar(np.array(data.data[var][idx])) for idx in index]\n",
    "            else:\n",
    "                print(var), type(data.data[var][index[0]])\n",
    "            \n",
    "            att = get_var_att(var)\n",
    "            if 'standardname' in att:\n",
    "                if len(att['standardname']) >0: dataout.standard_name = att['standardname'] \n",
    "                dataout.long_name = att['longname'] if len(att['longname']) > 0 else \"\"\n",
    "                if len(att['unit']) > 0: dataout.units = att['unit']\n",
    "                if len(att['min_v']) > 0: \n",
    "                    if 'int' in att['scaledtype']: \n",
    "                        dataout.valid_min = np.int16(att['min_v'])\n",
    "            elif 'double' in att['scaledtype']: \n",
    "                dataout.valid_min = float(att['min_v'])\n",
    "            else:\n",
    "                dataout.valid_min = float(att['min_v'])\n",
    "            if len(att['max_v']) > 0: \n",
    "                if 'int' in att['scaledtype']: \n",
    "                    dataout.valid_max = np.int16(att['max_v'])\n",
    "            elif 'double' in att['scaledtype']: \n",
    "                dataout.valid_max = float(att['max_v'])\n",
    "            else:\n",
    "                dataout.valid_max = float(att['max_v'])\n",
    "            if var == 'LAT': dataout.axis = 'Y'\n",
    "            if var == 'LON': dataout.axis = 'X'\n",
    "            #if len(att['min_v']) > 0:\n",
    "            #\tdataout.scale_factor = 1. \n",
    "            #\tdataout.add_offset = 0. \n",
    "            if 'flagvalues' in att:\n",
    "                if len(att['flagvalues']) >0: \n",
    "                    foo = att['flagvalues'].split(' ')\n",
    "                    dataout.flag_values = [np.int16(x) for x in foo] \n",
    "                    if len(att['flagmeanings']) >0: dataout.flag_meanings = att['flagmeanings'] \n",
    "                    if var != 'LAT' and var != 'LON':\n",
    "                            dataout.coordinates = \"time lat lon\" \n",
    "                            dataout.grid_mapping = \"crs\" \n",
    "                            dataout.cell_methods = \"time: point\" \n",
    "                            if len(att['comment']) > 0: dataout.comment = att['comment'] \n",
    "                            if len(get_ancillary(att['ancillary'],data.data.keys())) > 0: dataout.ancillary_variables = get_ancillary(att['ancillary'],data.data.keys())\n",
    "\n",
    "    \n",
    "            end = time.time()\n",
    "            #print var, end-start\n",
    "            #ftxt.write('Time used = %s sec\\n' %(end-start)); \n",
    "    #dataout.standard_name = \"sea_surface_temperature\" \n",
    "    #dataout.long_name = \"Sea surface temperature\" \n",
    "    #dataout.units = \"degree_Celsius\" \n",
    "    \n",
    "    #ftxt.write('Done with %s' %out_file)\n",
    "    ff.close()\n",
    "    #ftxt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
