{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import os\n",
    "from os.path import exists\n",
    "####################you will need to change some paths here!#####################\n",
    "#################################################################################\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import matplotlib as mpl\n",
    "#import openpyxl\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from math import cos, radians\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from netCDF4 import Dataset, date2index, num2date\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def listFD(url, ext=''):\n",
    "    page = requests.get(url).text\n",
    "    #print(page)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return [url + node.get('href') for node in soup.find_all('a') if (node.get('href').endswith(ext) and node.get('href').startswith('2'))]\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.mlab as mlaba\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from math import atan2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_nc='C:/Users/gentemann/Google Drive/f_drive/docs/projects/saildrone/data_so_far.nc'\n",
    "dataset = xr.open_dataset(filename_nc)\n",
    "\n",
    "date_1970 = dt.datetime(1970,1,1,0,0,0) # start date is1/1/1970\n",
    "#filename_out_nc='F:/data/cruise_data/saildrone/baja-2018/data_so_far.nc'\n",
    "#dataset = xr.open_dataset(filename_out_nc)\n",
    "ilen=(len(dataset.LAT['obs']))\n",
    "print(dataset.LAT[0,1].values*1)\n",
    "print(type(dataset))\n",
    "lats_usv=dataset.LAT[0,:].values\n",
    "lons_usv=dataset.LON[0,:].values\n",
    "tdim=len(lats_usv)\n",
    "tem_date=[0]*tdim #np.zeros(tdim)\n",
    "tem_dy_from=np.zeros(tdim)\n",
    "for i in range(0,tdim):\n",
    "    tem_dy=float(dataset.TIME[0,i].values)/86400000000000.\n",
    "    tem_dy_from[i]=float(dataset.TIME[0,i].values)/86400000000000.-float(dataset.TIME[0,0].values)/86400000000000.\n",
    "    date_usv[i]=date_1970+dt.timedelta(days=tem_dy)  #create new time array that can be queried for year etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lons_usv.min)\n",
    "print(lons_usv.max)\n",
    "print(lats_usv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tem_dyr=np.zeros(tdim)\n",
    "for i in range(0,tdim):\n",
    "    tem_dyr[i] = int(tem_date[i].timetuple().tm_yday)\n",
    "#print(tem_dyr[tem_dyr==day_of_year])\n",
    "\n",
    "# Bounds of the area\n",
    "lon_min, lon_max, lat_min, lat_max = lons_usv.min-1, lons_usv.max+1, lats_usv.min-1, lats_usv.max+1\n",
    "\n",
    "for incr_day in range(-55,1):\n",
    "    d = datetime.today() + timedelta(days=incr_day)\n",
    "    day_of_year = d.timetuple().tm_yday\n",
    "\n",
    "#    url = 'https://opendap.jpl.nasa.gov/opendap/OceanTemperature/ghrsst/data/GDS2/L3U/VIIRS_NPP/OSPO/v2.41/' \\\n",
    "#            + str(d.year) + '/' + str(day_of_year).zfill(3) + '/'\n",
    "    url = 'https://opendap.jpl.nasa.gov/opendap/OceanTemperature/ghrsst/data/GDS2/L2P/VIIRS_NPP/OSPO/v2.41/' \\\n",
    "            + str(d.year) + '/' + str(day_of_year).zfill(3) + '/'\n",
    "    ext = 'nc'\n",
    "\n",
    "    filenames=listFD(url, ext)\n",
    "    ilen=len(filenames)\n",
    "    inew_data=1\n",
    "    for ic in range(1,ilen):\n",
    "        file = filenames[ic]\n",
    "        print(file)\n",
    "        idyj=int(file[101:104])\n",
    "        ihr=int(file[113:115])\n",
    "        imin=int(file[115:117])\n",
    "        #rday_viirs=idyj+(ihr+(imin/60.))/24.\n",
    "        d_viirs=datetime(2018,imon,idym,ihr,imin)\n",
    "        \n",
    "        dataset = xr.open_dataset(file)\n",
    "#        lat = nc.attributes['minimum latitude']\n",
    "\n",
    "\n",
    "        # Select all observation in the area\n",
    "        subset = dataset.sel(\n",
    "            obs=(dataset.longitude > lon_min) & (dataset.longitude < lon_max) & (dataset.latitude > lat_min) & (dataset.latitude < lat_max))\n",
    "        # Create a mask with all track which go throught the area\n",
    "        # Create the subset with the mask\n",
    "        subset = dataset.isel(obs=np.in1d(dataset.sea_surface_temperature, subset.sea_surface_temperature))\n",
    "\n",
    "        for j in range(0,ilen_usv):\n",
    "            dist_x=((subset.longitude-lons_usv[j])**2+(subset.latitude-lats_usv[j])**2)**.5\n",
    "            dist_t=((subset.longitude-lons_usv[j])**2+(subset.latitude-lats_usv[j])**2)**.5\n",
    "            if dist_x<dist_usv[j]\n",
    "        #subset.latitude\n",
    "        #subset.to_netcdf('eddy_trajectory_amplitude_more40.nc')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
