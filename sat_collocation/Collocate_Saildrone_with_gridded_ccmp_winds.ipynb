{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Saildrone and CCMP collocation code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "\n",
    "def get_ccmp_filename(date):\n",
    "    dir_ccmp='F:/data/sat_data/ccmp/v02.0/'\n",
    "    syr, smon, sdym = str(date.dt.year.data), str(date.dt.month.data).zfill(2), str(date.dt.day.data).zfill(2)\n",
    "    ccmp_filename =dir_ccmp + 'Y' + syr + '/M' + smon + '/CCMP_Wind_Analysis_' + syr + smon + sdym + '_V02.0_L3.0_RSS.nc'\n",
    "    exists = os.path.isfile(ccmp_filename)\n",
    "    if exists==False:\n",
    "        ccmp_filename =dir_ccmp + 'Y' + syr + '/M' + smon + '/CCMP_RT_Wind_Analysis_' + syr + smon + sdym + '_V02.0_L3.0_RSS.nc'\n",
    "        exists = os.path.isfile(ccmp_filename)\n",
    "    return ccmp_filename, exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in USV data\n",
    "Read in the Saildrone USV file either from a local disc or using OpenDAP.\n",
    "\n",
    "There are 6 NaN values in the lat/lon data arrays, interpolate across these\n",
    "\n",
    "We want to collocate with wind vectors for this example,  but the wind vectors are only every 10 minutes rather than every minute, so use .dropna to remove all values in the dataset from all dataarrays when wind vectors aren't availalbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_collocation_data = 'F:/data/cruise_data/saildrone/baja-2018/ccmp_collocation_data.nc'\n",
    "#filename_usv = 'https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/allData/insitu/L2/saildrone/Baja/saildrone-gen_4-baja_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc'\n",
    "filename_usv='f:/data/cruise_data/saildrone/baja-2018/saildrone-gen_4-baja_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc'\n",
    "ds_usv = xr.open_dataset(filename_usv)\n",
    "ds_usv.close()\n",
    "ds_usv = ds_usv.isel(trajectory=0).swap_dims({'obs':'time'}).rename({'longitude':'lon','latitude':'lat'})\n",
    "ds_usv = ds_usv.sel(time=slice('2018-04-11T18:30',ds_usv.time[-1].data))  #first part of data is when USV being towed, elminiate\n",
    "ds_usv['lon'] = ds_usv.lon.interpolate_na(dim='time',method='linear') #there are 6 nan values\n",
    "ds_usv['lat'] = ds_usv.lat.interpolate_na(dim='time',method='linear')\n",
    "ds_usv['wind_speed']=np.sqrt(ds_usv.UWND_MEAN**2+ds_usv.VWND_MEAN**2)\n",
    "ds_usv['wind_dir']=np.arctan2(ds_usv.VWND_MEAN,ds_usv.UWND_MEAN)*180/np.pi\n",
    "ds_usv_subset = ds_usv.dropna(dim='time',subset={'UWND_MEAN'})   #get rid of all the nan\n",
    "#print(ds_usv_subset.UWND_MEAN[2000:2010].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use open_mfdataset you need to either provide a path or a list of filenames to input\n",
    "\n",
    "Here we use the USV cruise start and end date to read in all CCMP wind vector data for that period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_date,end_date = ds_usv_subset.time.min(),ds_usv_subset.time.max()\n",
    "filelist = []\n",
    "while read_date<=(end_date+np.timedelta64(1,'D')):\n",
    "    tem_filename, exists = get_ccmp_filename(read_date)\n",
    "    if exists:\n",
    "        filelist.append(tem_filename)\n",
    "    read_date=read_date+np.timedelta64(1,'D')\n",
    "#print(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CCMP data\n",
    "Read in data using open_mfdataset with the option coords='minimal'\n",
    "\n",
    "CCMP data uses long names for lat/lon so change that and then chage coordinate system to -180 to 180 from 0 to 360\n",
    "\n",
    "The dataset is printed out and you can see that rather than straight xarray data array for each of the data variables open_mfdataset using dask arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sat = xr.open_mfdataset(filelist,coords='minimal')\n",
    "ds_sat = ds_sat.rename({'longitude':'lon','latitude':'lat'}) \n",
    "ds_sat = ds_sat.assign_coords(lon=(((ds_sat.lon + 180) % 360) - 180)).sortby('lon').sortby('lat')\n",
    "ds_sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray interpolation won't run on chunked dimensions.  \n",
    "1. First let's subset the data to make it smaller to deal with by using the cruise lat/lons\n",
    "\n",
    "1. Now load the data into memory (de-Dask-ify) it  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 from above\n",
    "subset = ds_sat.sel(lon=slice(ds_usv_subset.lon.min().data,ds_usv_subset.lon.max().data),\n",
    "                    lat=slice(ds_usv_subset.lat.min().data,ds_usv_subset.lat.max().data))\n",
    "#Step 2 from above\n",
    "subset.load()\n",
    "#now collocate with usv lat and lons\n",
    "ds_collocated = subset.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='linear')\n",
    "ds_collocated_nearest = subset.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated['wind_speed']=np.sqrt(ds_collocated.uwnd**2+ds_collocated.vwnd**2)\n",
    "ds_collocated['wind_dir']=np.arctan2(ds_collocated.vwnd,ds_collocated.uwnd)*180/np.pi\n",
    "ds_collocated_nearest['wind_speed']=np.sqrt(ds_collocated_nearest.uwnd**2+ds_collocated_nearest.vwnd**2)\n",
    "ds_collocated_nearest['wind_dir']=np.arctan2(ds_collocated_nearest.vwnd,ds_collocated_nearest.uwnd)*180/np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((ds_collocated.uwnd-ds_usv_subset.UWND_MEAN).mean().data,(ds_collocated.uwnd-ds_usv_subset.UWND_MEAN).std().data)\n",
    "print((ds_collocated.vwnd-ds_usv_subset.VWND_MEAN).mean().data,(ds_collocated.vwnd-ds_usv_subset.VWND_MEAN).std().data)\n",
    "print((ds_collocated.wind_speed-ds_usv_subset.wind_speed).mean().data,(ds_collocated.wind_speed-ds_usv_subset.wind_speed).std().data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_collocated.time,ds_collocated.wind_speed-ds_usv_subset.wind_speed,'.-')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_collocated_nearest.time,ds_collocated_nearest.wind_speed-ds_usv_subset.wind_speed,'.-')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the idea here is that the USV data is being collocated repeatedly to the same CCMP data\n",
    "#rather than just interpolate the CCMP data onto the USV data, use nearest to interpolate the nearest CCMP value\n",
    "#now you can tell where the repeated data points are being collocated and this code\n",
    "#goes through the data and creates averages of the USV data that match the single CCMP collocated value\n",
    "ilen,index = ds_collocated_nearest.dims['time'],0\n",
    "ds_tem = ds_collocated_nearest.copy(deep=True)\n",
    "dus, duu, dvs, dvu, dut = [],[],[],[],[]\n",
    "while index < ilen:\n",
    "    if np.isnan(ds_collocated_nearest.uwnd[index]):\n",
    "        continue\n",
    "    test = ds_collocated_nearest.where((ds_tem.uwnd==ds_collocated_nearest.uwnd[index])&(ds_tem.vwnd==ds_collocated_nearest.vwnd[index]))\n",
    "    test = test/test\n",
    "    if test.uwnd.sum()>0:\n",
    "        np.append(dus,ds_collocated_nearest.uwnd[index])\n",
    "        np.append(duu,(ds_usv_subset.UWND_MEAN*test.uwnd).mean().data)\n",
    "        np.append(dvs,ds_collocated_nearest.vwnd[index])\n",
    "        np.append(dvs,(ds_usv_subset.VWND_MEAN*test.vwnd()).mean().data)\n",
    "        np.append(dut,ds_collocated_nearest.time[index])\n",
    "        ds_tem=ds_tem.where(np.isnan(test),np.nan)  #you have used values, so set to nan\n",
    "    index += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing code above\n",
    "ds_tem = ds_collocated_nearest.copy(deep=True)\n",
    "print(ds_collocated_nearest.uwnd[1055].data)\n",
    "print(ds_collocated_nearest.uwnd[1050:1150].data)\n",
    "test = ds_collocated_nearest.where((ds_collocated_nearest.uwnd==ds_collocated_nearest.uwnd[1055])&(ds_collocated_nearest.vwnd==ds_collocated_nearest.vwnd[1055]))\n",
    "test = test/test\n",
    "print(test.uwnd[1050:1150].data)\n",
    "ds_tem=ds_tem.where(np.isnan(test),np.nan)\n",
    "print(ds_tem.uwnd[1050:1150].data)\n",
    "print((ds_usv_subset.UWND_MEAN*test.uwnd).mean())\n",
    "print((ds_usv_subset.VWND_MEAN*test.vwnd).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_sat.lon[0:5])\n",
    "print(ds_sat.lon[1]-ds_sat.lon[0])\n",
    "print(ds_sat.lat[0:5])\n",
    "print(ds_sat.lat[1]-ds_sat.lat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv_subset_test = ds_usv_subset.copy(deep=True)\n",
    "ds_usv_subset_test['lon']=((np.round((ds_usv_subset.lon+179.875)/.25+1)-1)*.25)-179.875\n",
    "ds_usv_subset_test['lat']=((np.round((ds_usv_subset.lat+78.375)/.25+1)-1)*.25)-78.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_usv_subset.lon[0:500],ds_usv_subset.lat[0:500],'.-')\n",
    "plt.plot(ds_usv_subset_test.lon[0:500],ds_usv_subset_test.lat[0:500],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_usv_subset.interp(lon = ds_usv_subset_test.lon) #,lat = ds_usv_subset_test.lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats_usv=ds_usv.latitude.values\n",
    "lons_usv=ds_usv.longitude.values\n",
    "skin=ds_usv.TEMP_IR_UNCOR_MEAN.values\n",
    "tair=ds_usv.TEMP_AIR_MEAN.values\n",
    "bulk1=ds_usv.TEMP_CTD_MEAN.values\n",
    "bulk2=ds_usv.TEMP_O2_MEAN.values\n",
    "uspd=ds_usv.UWND_MEAN.values\n",
    "vspd=ds_usv.VWND_MEAN.values\n",
    "wing=ds_usv.HDG_WING.values\n",
    "wing_ang=ds_usv.WING_ANGLE.values\n",
    "pitch=ds_usv.PITCH.values\n",
    "heading=ds_usv.HDG_WING.values\n",
    "yaw_heading=ds_usv.HDG.values\n",
    "roll=ds_usv.ROLL.values\n",
    "tdim=len(skin)\n",
    "wdir=np.zeros(tdim)\n",
    "for i in range(0,tdim):\n",
    "    wdir[i]=atan2(vspd[i],uspd[i])*180/3.14159\n",
    "wspd=(uspd**2+vspd**2)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sat = get_ccmp(2018,170)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lat/lon from random file, it doesn't change\n",
    "ds_sat = get_ccmp(2003,1)\n",
    "lats_sat = ds_sat.lat\n",
    "lons_sat = ds_sat.lon\n",
    "ds_sat.close()\n",
    "#initialize variables\n",
    "latli_sv=-99\n",
    "lonli_sv=-99\n",
    "ihr_sv=-99\n",
    "col_count=0  #initialize\n",
    "gsst=np.zeros(tdim)\n",
    "gsst_num=np.zeros(tdim)\n",
    "#get goes data collocated with usv positions and times\n",
    "for i in range(0,10): #tdim):\n",
    "    latli = np.argmin( np.abs( lats_sat - lats_usv[i] ) )\n",
    "    lonli = np.argmin( np.abs( lons_sat - lons_usv[i] ) )\n",
    "    idy = ds_usv.time[i].dt.day.data        \n",
    "    if (latli!=latli_sv) or (lonli_sv!=lonli) or (idy_sv!=idy):  #need to read in new data\n",
    "        ds_sat = get_ccmp(ds_usv.time[i].dt.year.data,ds_usv.time[i].dt.dayofyear.data)\n",
    "        col_count += 1\n",
    "        gsst[i] = sat_sst\n",
    "        gsst_num[i] = col_count  #this is to keep track of when a new file read in or new collocation point\n",
    "        nc.close()\n",
    "        latli_sv=latli\n",
    "        lonli_sv=lonli\n",
    "        ihr_sv=ds_usv.time[i].dt.hour.data\n",
    "        print(i,tdim,lonli.data, latli.data,ihr_sv,gsst[i])\n",
    "    else:  #collocation is to same gsst point\n",
    "        gsst[i] = sat_sst \n",
    "        gsst_num[i] = col_count  #this is to keep track of when a new file read in or new collocation point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put into xarray dataset similiar in format to usv data\n",
    "gsst2=np.zeros((1,tdim))\n",
    "gsst_tem=np.zeros((1,tdim))\n",
    "gsst2[0,:]=gsst\n",
    "data_goes = xr.DataArray(gsst2, coords={'trajectory': ds_usv.trajectory,'obs': ds_usv.obs}, dims=('trajectory', 'obs'))\n",
    "gsst_tem[0,:]=gsst_num\n",
    "num_goes = xr.DataArray(gsst_tem, coords={'trajectory': ds_usv.trajectory,'obs': ds_usv.obs}, dims=('trajectory', 'obs'))\n",
    "xr_gsst = xr.Dataset({'goes_sst': data_goes, 'collocation_index': num_goes}, \n",
    "                     coords={'trajectory':ds_usv.trajectory, 'time':ds_usv.time, 'latitude':ds_usv.latitude, 'longitude':ds_usv.longitude})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_gsst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(filename_goes_sst, gsst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
