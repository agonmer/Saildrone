{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from math import atan2, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input filename\n",
    "dir_in='f:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/2018/'\n",
    "dir_out='f:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/'\n",
    "filename_in='f:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/l3r_temp.nc'\n",
    "\n",
    "#definitions and things you might have to set differently for each file\n",
    "itow_mask1=45 #see code just a bit below for figure to determine where to set flags here\n",
    "itow_mask2=-110 #see code just a bit below for figure to determine where to set flags here\n",
    "ISDP = 'Saildrone'\n",
    "SST_type = 'SSTdepth'\n",
    "Annex_version = '01.1'\n",
    "File_version = '01.0'\n",
    "astr_platform='SD1002'\n",
    "astr_title = 'Data from Saildrone cruise from SF to Guadalupe Island April-June 2018'\n",
    "astr_uuid = '0f410de6-4ba5-4f79-af20-8a57a445f454'\n",
    "droplist=['WWND_STDDEV', 'CHLOR_MEAN','RH_MEAN','WWND_MEAN','O2_CONC_STDDEV','CDOM_STDDEV',\n",
    "                          'TEMP_O2_STDDEV','BARO_PRES_MEAN','TEMP_O2_MEAN','SAL_STDDEV','TEMP_AIR_MEAN',\n",
    "                          'CDOM_MEAN','SAL_MEAN','O2_SAT_MEAN','CHLOR_STDDEV', 'COND_STDDEV', 'COND_MEAN',\n",
    "                          'BKSCT_RED_MEAN', 'TEMP_IR_MEAN', 'O2_SAT_STDDEV','O2_CONC_MEAN', 'TEMP_AIR_STDDEV', \n",
    "                          'BARO_PRES_STDDEV', 'TEMP_IR_STDDEV', 'VWND_STDDEV','RH_STDDEV', 'GUST_WND_STDDEV', 'GUST_WND_MEAN',\n",
    "                          'BKSCT_RED_STDDEV', 'UWND_STDDEV','HDG_WING','WING_ANGLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data back in, into two arrays one with time encoding and one without\n",
    "dataset=xr.open_dataset(filename_in,decode_times=False)\n",
    "dataset_decodetime=xr.open_dataset(filename_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85681"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mint=dataset_decodetime.TIME.min().data\n",
    "maxt=dataset_decodetime.TIME.max().data\n",
    "dataset.attrs['time_coverage_start']=str(np.datetime64(mint,'ms'))+'Z'\n",
    "dataset.attrs['time_coverage_end']=str(np.datetime64(maxt,'ms'))+'Z'\n",
    "ilen=(len(dataset.LAT['obs']))\n",
    "lats_usv=dataset.LAT[0,:].values\n",
    "lons_usv=dataset.LON[0,:].values\n",
    "dates_usv64=dataset_decodetime.TIME[0,:].values\n",
    "dates_usv=pd.to_datetime(dates_usv64, unit='ns')\n",
    "ilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the average distance between observations as the spatial resolution global attribute\n",
    "#import math\n",
    "#from math import cos\n",
    "# approximate radius of earth in km\n",
    "R = 6373.0 #km\n",
    "lat1 = np.deg2rad(lats_usv[1:ilen])\n",
    "lon1 = np.deg2rad(lons_usv[1:ilen])\n",
    "lat2 = np.deg2rad(lats_usv[0:ilen-1])\n",
    "lon2 = np.deg2rad(lons_usv[0:ilen-1])\n",
    "dlon = lon2 - lon1\n",
    "dlat = lat2 - lat1\n",
    "a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "c = 2 * np.arctan2(a**.5, (1 - a)**.5)\n",
    "distance = R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:/data/cruise_data/saildrone/baja-2018/daily_files/sd-1002/20180411180000-Saildrone-L3R-SSTdepth-CTD-NH_2632-v01.1-fv01.0.nc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicative_date_time=dates_usv[0].strftime(\"%Y%m%d%H%M%S\")\n",
    "Product_string = str(dataset.TEMP_CTD_MEAN.model_number) + '_' + str(dataset.TEMP_CTD_MEAN.serial_number)\n",
    "filename_L3R = dir_out + indicative_date_time + \\\n",
    "    '-' + ISDP + '-' + 'L3R' + '-' + SST_type + '-' +Product_string+ '-v' +Annex_version+ '-fv' +File_version+ '.nc'\n",
    "filename_L3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add global attributes that are missing\n",
    "#some of these will need to be changed for new cruises\n",
    "dataset.attrs['title'] = astr_title\n",
    "dataset.attrs['summary'] = 'none'\n",
    "dataset.attrs['references'] = 'none'\n",
    "dataset.attrs['institution'] = 'Saildrone'\n",
    "dataset.attrs['history'] = 'Saildrone 6-hourly v1 files were used to create this file'\n",
    "dataset.attrs['comment'] = 'none'\n",
    "dataset.attrs['license'] = 'free and open'\n",
    "dataset.attrs['id'] = 'SSTdepth'\n",
    "dataset.attrs['naming_authority'] = 'org.shipborne-radiometer'\n",
    "dataset.attrs['product_version'] = '1.0'\n",
    "dataset.attrs['uuid'] = astr_uuid \n",
    "dataset.attrs['l2r_version_id'] = '1.1' \n",
    "dataset.attrs['netcdf_version_id'] = '4.6.1'\n",
    "dataset.attrs['date_created'] = dt.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\") #yyyy-mm-ddThh:mm:ssZ\n",
    "dataset.attrs['file_quality_level'] = 3\n",
    "dataset.attrs['spatial_resolution'] = str(distance.mean()*1000)+' m'\n",
    "dataset.attrs['start_time'] = dates_usv[0].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "dataset.attrs['time_coverage_start'] = dates_usv[0].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "dataset.attrs['stop_time'] = dates_usv[-1].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "dataset.attrs['time_coverage_end'] = dates_usv[-1].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "dataset.attrs['northernmost_latitude'] = lats_usv.max()\n",
    "dataset.attrs['geospatial_lat_max'] = lats_usv.max()\n",
    "dataset.attrs['southernmost_latitude'] = lats_usv.min()\n",
    "dataset.attrs['geospatial_lat_min'] = lats_usv.min()\n",
    "dataset.attrs['easternmost_longitude'] = lons_usv.max()\n",
    "dataset.attrs['geospatial_lon_max'] = lons_usv.max()\n",
    "dataset.attrs['westernmost_longitude'] = lons_usv.min()\n",
    "dataset.attrs['geospatial_lon_min'] = lons_usv.min()\n",
    "dataset.attrs['geospatial_lat_units'] = 'degrees_north'\n",
    "dataset.attrs['geospatial_lon_units'] = 'degrees_east'\n",
    "dataset.attrs['source'] = 'SSTdepth, wind_speed'\n",
    "dataset.attrs['platform'] = astr_platform\n",
    "dataset.attrs['sensor'] = str(dataset.TEMP_CTD_MEAN.sensor_description + '_' +\\\n",
    "            dataset.TEMP_CTD_MEAN.model_number + '_' + dataset.TEMP_CTD_MEAN.serial_number + ', ' + \\\n",
    "            dataset.UWND_MEAN.sensor_description + '_' + dataset.UWND_MEAN.model_number + '_' + \\\n",
    "                    dataset.UWND_MEAN.serial_number)\n",
    "dataset.attrs['metadata_link'] = 'TBD'\n",
    "dataset.attrs['keywords'] = 'Oceans > Ocean Temperature > Sea Surface Temperature'\n",
    "dataset.attrs['keywords_vocabulary'] = 'NASA Global Change Master Directory (GCMD) Science Keywords'\n",
    "dataset.attrs['acknowledgment'] = 'The Schmidt Family Foundation, Saildrone, NASA Physical Oceanography'\n",
    "dataset.attrs['project'] = 'International Shipborne Radiometer Network'\n",
    "dataset.attrs['publisher_name'] = 'The ISRN Project Office'\n",
    "dataset.attrs['publisher_url'] = 'http://www.shipborne.radiometer.org'\n",
    "dataset.attrs['publisher_email'] = 'info@shipborne-radiometer.org'\n",
    "dataset.attrs['processing_level'] = '1.0'\n",
    "del dataset.attrs['nodc_template_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the attributes from uwnd_mean cause they are nice, add required CF ones too\n",
    "#create wind_speed varible\n",
    "dataset_tem=dataset.copy(deep=True)\n",
    "attrs = dataset.UWND_MEAN.attrs.copy()\n",
    "attrs['standard_name'] = 'wind_speed'\n",
    "attrs['long_name'] = 'wind_speed'\n",
    "attrs['valid_min'] = 0\n",
    "attrs['valid_max'] = 100\n",
    "attrs['source'] = 'anemometer'\n",
    "attrs['comment'] = 'Instrument located at to of Saildrone mast at ' +\\\n",
    "                str(dataset.UWND_MEAN.installed_height)+' m' + '.  This was adjusted ' +\\\n",
    "                'to 10 m as ws_10m = ws*log(10./1e-4))/log(WS_height/1e-4'\n",
    "attrs['height'] = '10 m' #str(str(dataset.UWND_MEAN.installed_height)+' m')\n",
    "WS=(dataset['UWND_MEAN']**2+dataset['VWND_MEAN']**2)**.5\n",
    "WS_height=int(dataset.UWND_MEAN.installed_height)\n",
    "WS_10m = (WS*log(10./1e-4))/log(WS_height/1e-4)\n",
    "#dataset2['wind_speed']=\n",
    "dataset['wind_speed']=WS_10m\n",
    "dataset.wind_speed.attrs=attrs\n",
    "\n",
    "#copy the attributes from uwnd_mean cause they are nice, add required CF ones too\n",
    "#create wind_direction varible\n",
    "attrs = dataset.UWND_MEAN.attrs.copy()\n",
    "attrs['standard_name'] = 'wind_to_direction'\n",
    "attrs['long_name'] = 'local wind direction'\n",
    "attrs['valid_min'] = 0\n",
    "attrs['valid_max'] = 360\n",
    "attrs['units'] = 'degrees'\n",
    "attrs['source'] = 'anemometer'\n",
    "attrs['height'] = str(str(dataset.UWND_MEAN.installed_height)+' m')\n",
    "WD=np.arctan2(dataset.VWND_MEAN,dataset.UWND_MEAN)\n",
    "dataset['wind_direction']=WD\n",
    "dataset.wind_direction.attrs=attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename into that names that are CF compliant\n",
    "#need to check with JFP about _mean vs inst ob\n",
    "dataset_tem=dataset.copy(deep=True)\n",
    "dataset_tem2=dataset.copy(deep=True)\n",
    "\n",
    "dataset_tem2['TEMP_CTD_MEAN'] = dataset_tem['TEMP_CTD_MEAN'].astype(np.float32,copy=False)\n",
    "attrs = dataset.TEMP_CTD_MEAN.attrs.copy()\n",
    "dataset_tem2.TEMP_CTD_MEAN.attrs=attrs\n",
    "dataset_tem2['LAT'] = dataset_tem['LAT'].astype(np.float32,copy=False)\n",
    "attrs = dataset.LAT.attrs.copy()\n",
    "dataset_tem2.LAT.attrs=attrs\n",
    "dataset_tem2['LON'] = dataset_tem['LON'].astype(np.float32,copy=False)\n",
    "attrs = dataset.LON.attrs.copy()\n",
    "dataset_tem2.LON.attrs=attrs\n",
    "dataset_tem2['TEMP_CTD_MEAN'] = dataset_tem['TEMP_CTD_MEAN'].astype(np.float32,copy=False)\n",
    "attrs = dataset.TEMP_CTD_MEAN.attrs.copy()\n",
    "dataset_tem2.TEMP_CTD_MEAN.attrs=attrs\n",
    "dataset_tem2['COG'] = dataset_tem['COG'].astype(np.float32,copy=False)\n",
    "attrs = dataset.COG.attrs.copy()\n",
    "dataset_tem2.COG.attrs=attrs\n",
    "dataset_tem2['HDG'] = dataset_tem['HDG'].astype(np.float32,copy=False)\n",
    "attrs = dataset.HDG.attrs.copy()\n",
    "dataset_tem2.HDG.attrs=attrs\n",
    "dataset_tem2['ROLL'] = dataset_tem['ROLL'].astype(np.float32,copy=False)\n",
    "attrs = dataset.ROLL.attrs.copy()\n",
    "dataset_tem2.ROLL.attrs=attrs\n",
    "dataset_tem2['PITCH'] = dataset_tem['PITCH'].astype(np.float32,copy=False)\n",
    "attrs = dataset.PITCH.attrs.copy()\n",
    "dataset_tem2.PITCH.attrs=attrs\n",
    "dataset_tem2['SOG'] = dataset_tem['SOG'].astype(np.float32,copy=False)\n",
    "attrs = dataset.SOG.attrs.copy()\n",
    "dataset_tem2.SOG.attrs=attrs\n",
    "dataset_tem2['TEMP_CTD_STDDEV'] = dataset_tem['TEMP_CTD_STDDEV'].astype(np.float32,copy=False)\n",
    "attrs = dataset.TEMP_CTD_STDDEV.attrs.copy()\n",
    "dataset_tem2.TEMP_CTD_STDDEV.attrs=attrs\n",
    "dataset_tem2['wind_speed'] = dataset_tem['wind_speed'].astype(np.float32,copy=False)\n",
    "attrs = dataset.wind_speed.attrs.copy()\n",
    "dataset_tem2.wind_speed.attrs=attrs\n",
    "dataset_tem2['wind_direction'] = dataset_tem['wind_direction'].astype(np.float32,copy=False)\n",
    "attrs = dataset.wind_direction.attrs.copy()\n",
    "dataset_tem2.wind_direction.attrs=attrs\n",
    "dataset_tem2['TIME'] = dataset_tem['TIME'].astype(np.float32,copy=False)\n",
    "attrs = dataset.TIME.attrs.copy()\n",
    "dataset_tem2.TIME.attrs=attrs\n",
    "\n",
    "dataset2 = dataset_tem2.copy(deep=True)\n",
    "dataset2 = dataset_tem2.rename(\n",
    "    {'TEMP_CTD_MEAN': 'sea_water_temperature',\n",
    "     'COG': 'course_over_ground',\n",
    "     'LAT': 'lat',\n",
    "     'LON': 'lon',\n",
    "     'TIME': 'time',\n",
    "     'HDG': 'true_bearing',\n",
    "     'ROLL': 'platform_roll',\n",
    "     'PITCH': 'platform_pitch',\n",
    "     'SOG': 'speed_over_ground',\n",
    "    'TEMP_CTD_STDDEV':'sst_total_uncertainty'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add missing attributes to sea_water_temperature\n",
    "dataset2['sea_water_temperature'].values=dataset2['sea_water_temperature'].values+273.15 #change to kelvin\n",
    "attrs = dataset.TEMP_CTD_MEAN.attrs.copy()\n",
    "dataset2.sea_water_temperature.attrs=attrs\n",
    "dataset2.sea_water_temperature.attrs['valid_min']=260.0\n",
    "dataset2.sea_water_temperature.attrs['valid_max']=320.0\n",
    "dataset2.sea_water_temperature.attrs['units']='kelvin'\n",
    "dataset2.sea_water_temperature.attrs['long_name']='sea surface depth temperature at 0.6m'\n",
    "dataset2.time.attrs['standard_name']='time'\n",
    "dataset2.time.attrs['long_name']='time'\n",
    "dataset2.lon.attrs['standard_name']='longitude'\n",
    "dataset2.lon.attrs['long_name']='longitude'\n",
    "dataset2.lat.attrs['long_name']='latitude'\n",
    "dataset2.lat.attrs['standard_name']='latitude'\n",
    "dataset2.true_bearing.attrs['long_name']='platform true bearing'\n",
    "dataset2.true_bearing.attrs['standard_name']='platform_orientation'\n",
    "dataset2.speed_over_ground.attrs['long_name']='platform speed over ground'\n",
    "dataset2.sst_total_uncertainty.attrs['standard_name']='sea_water_temperature standard error'\n",
    "dataset2.sst_total_uncertainty.attrs['long_name']=' sea water temperature total uncertainty'\n",
    "dataset2.sst_total_uncertainty.attrs['valid_min']=0.0\n",
    "dataset2.sst_total_uncertainty.attrs['valid_max']=2.0\n",
    "dataset2.sst_total_uncertainty.attrs['units']='kelvin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'quality_level' (trajectory: 1, obs: 85681)>\n",
       "array([[2, 2, 2, ..., 2, 2, 2]], dtype=int8)\n",
       "Coordinates:\n",
       "  * trajectory  (trajectory) float32 1002.0\n",
       "Dimensions without coordinates: obs\n",
       "Attributes:\n",
       "    flag_meanings:  no_data bad_data worst_quality low_quality acceptable_qua...\n",
       "    coordinates:    time\n",
       "    flag_values:    [0 1 2 3 4 5]\n",
       "    long_name:      measurement quality value"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_bytes=np.byte((0,1,2,3,4,5)) #bytearray([0,1,2,3,4,5])\n",
    "iobs=dataset2.dims['obs']\n",
    "iqual_byte = np.ones(shape=(iobs,1), dtype='b')*5  #change byte to b1\n",
    "iqual_byte[:itow_mask1] = 2  #set at top of file from looking at data\n",
    "iqual_byte[itow_mask2:] = 2\n",
    "attrs = {'long_name': 'measurement quality value','coordinates': 'time',\n",
    "         'flag_meanings': 'no_data bad_data worst_quality low_quality acceptable_quality best_quality',\n",
    "         'flag_values': flag_bytes }\n",
    "({'obs': ('obs', [0, 1, 2, 3], attrs)})\n",
    "dataset2['quality_level'] = (('trajectory', 'obs'), iqual_byte.T)\n",
    "dataset2.quality_level.attrs=attrs\n",
    "dataset2.quality_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset2 = dataset2.drop(['UWND_MEAN','VWND_MEAN','trajectory'])\n",
    "dataset2 = dataset2.drop(['UWND_MEAN','VWND_MEAN'])\n",
    "dataset2=dataset2.squeeze()\n",
    "dataset2 = dataset2.rename({'obs':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2['sea_water_temperature'].attrs['coordinates']='time'\n",
    "dataset2['sst_total_uncertainty'].attrs['coordinates']='time'\n",
    "dataset2['speed_over_ground'].attrs['coordinates']='time'\n",
    "dataset2['course_over_ground'].attrs['coordinates']='time'\n",
    "dataset2['platform_roll'].attrs['coordinates']='time'\n",
    "dataset2['platform_pitch'].attrs['coordinates']='time'\n",
    "dataset2['true_bearing'].attrs['coordinates']='time'\n",
    "dataset2['wind_speed'].attrs['coordinates']='time'\n",
    "dataset2['wind_direction'].attrs['coordinates']='time'\n",
    "dataset2['quality_level'].attrs['coordinates']='time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'platform_pitch' (time: 85681)>\n",
       "array([0.7, 0.8, 1. , ..., 1.4, 1.3, 1.2], dtype=float32)\n",
       "Coordinates:\n",
       "    trajectory  float32 1002.0\n",
       "Dimensions without coordinates: time\n",
       "Attributes:\n",
       "    standard_name:  platform_pitch_angle\n",
       "    long_name:      Pitch\n",
       "    coordinates:    time\n",
       "    units:          degree"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['platform_pitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#JF If I # these lines out it won't write out\n",
    "#If I del the coordinates then writes out, but without coordinates\n",
    "\n",
    "#del dataset2['sea_water_temperature'].attrs['coordinates']\n",
    "#del dataset2['sst_total_uncertainty'].attrs['coordinates']\n",
    "#del dataset2['speed_over_ground'].attrs['coordinates']\n",
    "#del dataset2['course_over_ground'].attrs['coordinates']\n",
    "#del dataset2['platform_roll'].attrs['coordinates']\n",
    "#del dataset2['platform_pitch'].attrs['coordinates']\n",
    "#del dataset2['true_bearing'].attrs['coordinates']\n",
    "#del dataset2['wind_speed'].attrs['coordinates']\n",
    "#del dataset2['wind_direction'].attrs['coordinates']\n",
    "#del dataset2['quality_level'].attrs['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot serialize coordinates because variable sea_water_temperature already has an attribute 'coordinates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f3628f42c744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#comp = dict(coordinates='time')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#encoding = {var: comp for var in dataset2.data_vars}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mdataset2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_L3R\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, encoding=encoding)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mfilename_L3R\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m   1135\u001b[0m         return to_netcdf(self, path, mode, format=format, group=group,\n\u001b[0;32m   1136\u001b[0m                          \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m                          unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     def to_zarr(self, store=None, mode='w-', synchronizer=None, group=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, writer, encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         dataset.dump_to_store(store, sync=sync, encoding=encoding,\n\u001b[1;32m--> 657\u001b[1;33m                               unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36mdump_to_store\u001b[1;34m(self, store, encoder, sync, encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m         \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconventions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_dataset_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[0mcheck_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\conventions.py\u001b[0m in \u001b[0;36mencode_dataset_coordinates\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[0mnon_dim_coord_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m     return _encode_coordinates(dataset._variables, dataset.attrs,\n\u001b[1;32m--> 717\u001b[1;33m                                non_dim_coord_names=non_dim_coord_names)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xarray\\conventions.py\u001b[0m in \u001b[0;36m_encode_coordinates\u001b[1;34m(variables, attributes, non_dim_coord_names)\u001b[0m\n\u001b[0;32m    678\u001b[0m             raise ValueError('cannot serialize coordinates because variable '\n\u001b[0;32m    679\u001b[0m                              \u001b[1;34m\"%s already has an attribute 'coordinates'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m                              % var_name)\n\u001b[0m\u001b[0;32m    681\u001b[0m         \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoord_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot serialize coordinates because variable sea_water_temperature already has an attribute 'coordinates'"
     ]
    }
   ],
   "source": [
    "#xarray to_netcdf function doesn't handle encoding vs set attributes very well.  for some of\n",
    "#the variables, there is secret encoding that doesn't print out when you look at the variable.\n",
    "#So, if you set an attribute that conflicts with encodings, when you try to to_netcdf output the file\n",
    "#you get a really odd error about overwriting attributes.  In order to see the encodings you have to look here:\n",
    "#dataset3.platform_pitch.encoding\n",
    "#you can either set the encoded values directly dataset3.platform_pitch.encoding['_FillValue']=-1.0\n",
    "#or you set it when writing the file out as done below\n",
    "dataset2.quality_level.attrs['_FillValue']=-128\n",
    "dataset2.sst_total_uncertainty.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.sea_water_temperature.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.speed_over_ground.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.platform_roll.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.true_bearing.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.course_over_ground.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.platform_pitch.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.lon.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.wind_speed.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.wind_direction.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.time.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.lat.attrs['_FillValue']=-9.96921e+36\n",
    "dataset2.lat.attrs['standard_name']='latitude'\n",
    "dataset2.lon.attrs['standard_name']='longitude'\n",
    "#comp = dict(_FillValue=-9.96921e+36)\n",
    "#encoding = {var: comp for var in dataset4.data_vars}\n",
    "#encoding['quality_level']=-128\n",
    "#print(encoding)\n",
    "#comp = dict(coordinates='time')\n",
    "#encoding = {var: comp for var in dataset2.data_vars}\n",
    "dataset2.to_netcdf(filename_L3R) #, encoding=encoding)\n",
    "filename_L3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
